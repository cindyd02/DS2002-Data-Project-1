{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tabulate\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Installing collected packages: tabulate\n",
      "Successfully installed tabulate-0.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Data File Ingestion Summary ---\n",
      "No summary available for this data format.\n",
      "Saved data to table 't20_wc_batting_summary' in etl_data.db\n",
      "\n",
      "First 5 rows of table 't20_wc_batting_summary':\n",
      "+----------------------+---------------+--------------+------------------------+---------------------------------+--------+---------+------+------+--------+\n",
      "| match                | teamInnings   |   battingPos | batsmanName            | dismissal                       |   runs |   balls |   4s |   6s |     SR |\n",
      "+======================+===============+==============+========================+=================================+========+=========+======+======+========+\n",
      "| Namibia Vs Sri Lanka | Namibia       |            1 | Michael van Lingen     | c Pramod Madushan b Chameera    |      3 |       6 |    0 |    0 |  50    |\n",
      "+----------------------+---------------+--------------+------------------------+---------------------------------+--------+---------+------+------+--------+\n",
      "| Namibia Vs Sri Lanka | Namibia       |            2 | Divan la Cock          | c Shanaka b Pramod Madushan     |      9 |       9 |    1 |    0 | 100    |\n",
      "+----------------------+---------------+--------------+------------------------+---------------------------------+--------+---------+------+------+--------+\n",
      "| Namibia Vs Sri Lanka | Namibia       |            3 | Jan Nicol Loftie-Eaton | c â€ Mendis b Karunaratne         |     20 |      12 |    1 |    2 | 166.66 |\n",
      "+----------------------+---------------+--------------+------------------------+---------------------------------+--------+---------+------+------+--------+\n",
      "| Namibia Vs Sri Lanka | Namibia       |            4 | Stephan Baard          | c DM de Silva b Pramod Madushan |     26 |      24 |    2 |    0 | 108.33 |\n",
      "+----------------------+---------------+--------------+------------------------+---------------------------------+--------+---------+------+------+--------+\n",
      "| Namibia Vs Sri Lanka | Namibia       |            5 | Gerhard Erasmus(c)     | c Gunathilaka b PWH de Silva    |     20 |      24 |    0 |    0 |  83.33 |\n",
      "+----------------------+---------------+--------------+------------------------+---------------------------------+--------+---------+------+------+--------+\n",
      "\n",
      "--- Post Processing Summary ---\n",
      "Summary:\n",
      "Number of records: 699\n",
      "Number of columns: 11\n",
      "Column names:\n",
      "- match\n",
      "- teamInnings\n",
      "- battingPos\n",
      "- batsmanName\n",
      "- dismissal\n",
      "- runs\n",
      "- balls\n",
      "- 4s\n",
      "- 6s\n",
      "- SR\n",
      "- NewColumn\n",
      "\n",
      "--- Summary Comparison ---\n",
      "Input:  0 records, 0 columns\n",
      "Output: 699 records, 11 columns\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import sqlite3\n",
    "import os\n",
    "from tabulate import tabulate\n",
    "\n",
    "def load_data(file_path, file_type):\n",
    "    try:\n",
    "        if file_type == 'json':\n",
    "            with open(file_path, 'r') as file:\n",
    "                return json.load(file)\n",
    "        elif file_type == 'csv':\n",
    "            return pd.read_csv(file_path)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported file type\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        return None\n",
    "\n",
    "def json_to_csv(json_data, output_path):\n",
    "    try:\n",
    "        data = pd.json_normalize(json_data, 'battingSummary')\n",
    "        data.to_csv(output_path, index=False)\n",
    "        print(f\"Converted JSON to CSV at {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting JSON to CSV: {e}\")\n",
    "\n",
    "def csv_to_json(csv_data, output_path):\n",
    "    try:\n",
    "        csv_data.to_json(output_path, orient='records', indent=4)\n",
    "        print(f\"Converted CSV to JSON at {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting CSV to JSON: {e}\")\n",
    "\n",
    "def modify_columns(data, add_columns=None, drop_columns=None):\n",
    "    if add_columns:\n",
    "        for col_name, value in add_columns.items():\n",
    "            data[col_name] = value\n",
    "    if drop_columns:\n",
    "        data = data.drop(columns=drop_columns)\n",
    "    return data\n",
    "\n",
    "def save_to_db(data, table_name, db_name='etl_data.db'):\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_name)\n",
    "        data.to_sql(table_name, conn, if_exists='replace', index=False)\n",
    "        print(f\"Saved data to table '{table_name}' in {db_name}\")\n",
    "        conn.close()\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving to database: {e}\")\n",
    "\n",
    "def generate_summary(data):\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        num_records = len(data)\n",
    "        num_columns = len(data.columns)\n",
    "        print(f\"Summary:\")\n",
    "        print(f\"Number of records: {num_records}\")\n",
    "        print(f\"Number of columns: {num_columns}\")\n",
    "        print(\"Column names:\")\n",
    "        for col in data.columns:\n",
    "            print(f\"- {col}\")\n",
    "        return num_records, num_columns\n",
    "    else:\n",
    "        print(\"No summary available for this data format.\")\n",
    "        return 0, 0\n",
    "\n",
    "def display_sqlite_table(db_name, table_name):\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_name)\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(f\"SELECT * FROM {table_name} LIMIT 5\")\n",
    "        rows = cursor.fetchall()\n",
    "        headers = [description[0] for description in cursor.description]\n",
    "        print(f\"\\nFirst 5 rows of table '{table_name}':\")\n",
    "        print(tabulate(rows, headers=headers, tablefmt=\"grid\"))\n",
    "        conn.close()\n",
    "    except Exception as e:\n",
    "        print(f\"Error displaying SQLite table: {e}\")\n",
    "\n",
    "def etl_pipeline(input_file, input_type, output_type, modify=True):\n",
    "    data = load_data(input_file, input_type)\n",
    "    if data is None:\n",
    "        return\n",
    "\n",
    "    print(\"\\n--- Data File Ingestion Summary ---\")\n",
    "    input_records, input_columns = generate_summary(data)\n",
    "\n",
    "    if input_type == 'json' and output_type == 'csv':\n",
    "        json_to_csv(data, 'output.csv')\n",
    "        output_data = pd.read_csv('output.csv')\n",
    "    elif input_type == 'csv' and output_type == 'json':\n",
    "        csv_to_json(data, 'output.json')\n",
    "        with open('output.json', 'r') as f:\n",
    "            output_data = json.load(f)\n",
    "    elif output_type == 'sql':\n",
    "        if input_type == 'json':\n",
    "            data = pd.json_normalize(data, 'battingSummary')\n",
    "        table_name = os.path.splitext(os.path.basename(input_file))[0]\n",
    "        save_to_db(data, table_name)\n",
    "        display_sqlite_table('etl_data.db', table_name)\n",
    "        output_data = data\n",
    "    else:\n",
    "        output_data = data\n",
    "\n",
    "    if modify and isinstance(output_data, pd.DataFrame):\n",
    "        output_data = modify_columns(output_data, add_columns={'NewColumn': 0})\n",
    "\n",
    "    print(\"\\n--- Post Processing Summary ---\")\n",
    "    output_records, output_columns = generate_summary(output_data)\n",
    "\n",
    "    print(\"\\n--- Summary Comparison ---\")\n",
    "    print(f\"Input:  {input_records} records, {input_columns} columns\")\n",
    "    print(f\"Output: {output_records} records, {output_columns} columns\")\n",
    "\n",
    "def main():\n",
    "    input_file = input(\"Enter the input file name: \")\n",
    "    input_type = input(\"Enter the input file type (csv/json): \").lower()\n",
    "    output_type = input(\"Enter the desired output type (csv/json/sql): \").lower()\n",
    "\n",
    "    etl_pipeline(input_file, input_type, output_type)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
